{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiscale Basics Tutorial\n",
    "\n",
    "*By R. Bulanadi, 28/01/20*\n",
    "\n",
    "***\n",
    "While Project Multiscale is currently very powerful, it has a slight learning curve to understand the required functions for basic use. This notebook has been written to teach the basics of using Project Multiscale functions, by binarising the Phase channels of microscopy data obtained from a Cypher Asylum AFM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Project Multiscale, the Multiscale package must be loaded. Load it as below, being sure to change the directory to lead to your Multiscale package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/ralph/Code/Project_Multiscale/') #Change to your Multiscale Directory\n",
    "from multiscale.processing import twodim\n",
    "from multiscale.processing import core as pt\n",
    "import multiscale.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert our raw data (`.ibw` format) into the `.hdf5` format used by Project Multiscale. First, we will set the name of both our raw `.ibw` file, and the new `.hdf5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_filename = 'SD_P4_zB5_050mV_-2550mV_0002.ibw'\n",
    "filename = original_filename.split('.')[0]+'.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `multiscale.io` package handles file conversion. In general, one can call `multiscale.io.read_file.tohdf5` to convert the data type.\n",
    "\n",
    "*If the data type is not currently compatible, either code a conversion function or ask Loic/Ralph/Iaroslav.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiscale.io.read_file.tohdf5(original_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open the newly produced file `SD_P4_zB5_050mV_-2550mV_0002` in HDFView, you will see four folders:\n",
    "1. **`datasets`** contains the main converted data from the .ibw files. It contains a subfolder for each of the original scans (in this case, only one), and each of these subfolders contain the 8 data channels obtained from the raw data.\n",
    "2. **`metadata`** contains all other data obtained from the .ibw files, except for the image itself, such as the scan rate or tip voltage.\n",
    "3. **`process`** is currently empty, but will eventually contain the results of our subsequent processing.\n",
    "4. **`type`** indicates the original filetype of the data - that is, 'ibw'.\n",
    "\n",
    "**Warning: HDFView prevents Python from operating on open .hdf5 files. Make sure to close the open files before proceeding!**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any processing, let's just check if things work. The function `twodim.save_image` lets us save an image from an array - however, our array is stored in the `.hdf5` file, and Python does not currently know about it. To use `twodim.save_image` then, we call it using the `pt.m_apply` function.\n",
    "\n",
    "In short, `pt.m_apply` lets us pass the location of the files within the `.hdf5` file, instead of an actual array. This makes handling several datasets much easier. For now, the main function call of `pt.m_apply` is of the format:\n",
    "\n",
    "`m_apply(filename, function, in_paths)`\n",
    "\n",
    "1. **`filename`** The name of the `.hdf5` file we are using. We set this earlier to be `'SD_P4_zB5_050mV_-2550mV_0002.hdf5'`\n",
    "2. **`function`** The function we are applying. In this case, we are going to use the function `twodim.save_image`.\n",
    "3. **`in_paths`** This is the path (or paths) to the data within the `.hdf5` file. If you look in HDFView, you can see the file directory. In this case, let's look at the `Phase1Trace` channel in `datasets`. We will thus set this argument to `'datasets/SD_P4_zB5_050mV_-2550mV_0002/Phase1Trace'`\n",
    "\n",
    "**Note:** Other arguments exist, but are beyond this scope. See Intermediate or Programming tutorials for more detail\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.m_apply(filename, twodim.save_image, 'datasets/SD_P4_zB5_050mV_-2550mV_0002/Phase2Retrace', image_name = 'Original_Phase', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice we added extra arguments to `m_apply`. In general, if `m_apply` is given extra arguments, these arguments are passed to the subfunction: in this case, `twodim.save_image`. Thus, `twodim.save_image` knows to set `image_name` to `'Original_Phase'`, and to set `show` to `True`. You should now also see the image saved in this fiel directory; if you want, you could change this by changing the variable `saving_path`\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have something to compare to, we can begin processing. We are going to linearise the phase of this image (that is, transform the phase, which is currently an angle between -90 and 270, and wrapping at that limit) to a number between 0 and 1. To do this, we are going to use the function phase_linearisation, which we will again call using `m_apply`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.m_apply(filename, twodim.phase_linearisation, 'datasets/SD_P4_zB5_050mV_-2550mV_0002/Phase2Retrace')\n",
    "print('Linearisation Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open HDFView right now, you should see a new folder in `process` called `001-phase_linearisation` which contains the newly linearised data. If an error did occur at some point, you might also see other files of the form `abc-phase_linearisation`, where abc is some number. Don't worry; simply mark the correct (or incorrect) ones, and change the path names of the next function calls to ensure it goes to the correct folder.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is linearised, we can now binarise it. This is simply a threshold function. This is called very similarly to the last function, except for the different function call, and the different path location. Feel free to look at the code itself in the `twodim` subpackage if y7ou want to see how this code works, or if you want to pass it other arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.m_apply(filename, twodim.phase_binarisation, 'process/001-phase_linearisation/SD_P4_zB5_050mV_-2550mV_0002/Phase2Retrace')\n",
    "print('Binarisation Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can view our final image. This requires the `twodim.save_image` function, which we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.m_apply(filename, twodim.save_image, 'process/002-phase_binarisation/SD_P4_zB5_050mV_-2550mV_0002/Phase2Retrace', image_name = 'Binarised_Phase', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to, we can also go back and see the intermediate, linearised phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.m_apply(filename, twodim.save_image, 'process/001-phase_linearisation/SD_P4_zB5_050mV_-2550mV_0002/Phase2Retrace', image_name = 'Linearised_Phase', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ends the basic multiscale tutorial. As shown so far, Multiscale allows you to keep track of all of your variables and intermediate steps. Since they are saved permanently to the `.hdf5` file, they will remain so long as you don't delete it. Any function that works with arrays can also be passed directly into m_apply, and you also gain access to the current repository of functions.\n",
    "\n",
    "If you want to apply on multiple datafiles concurrently, or use more complicated functions that require thus (such as distortion correction) please see the Intermediate tutorial. If you want to use Multiscale in more depth after, please check the Programming tutorial.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "**OSError: Unable to create file**\n",
    "\n",
    "Close the file in HDFView!\n",
    "\n",
    "**KeyError: 'Unable to open object (component not found)'**\n",
    "\n",
    "Make sure your `in_path` is correct. Open the file, and make sure that all your process numbers (ie, the 002) is the same as in your function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
